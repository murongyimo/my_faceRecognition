{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#加载程序中定义的常量和函数\n",
    "import inference\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载的时间间隔。\n",
    "# EVAL_INTERVAL_SECS = 10\n",
    "\n",
    "# def evaluate(valid_data):\n",
    "#     n_valid_examples = len(valid_data[0])\n",
    "#     with tf.Graph().as_default() as g:\n",
    "#         x = tf.placeholder(tf.float32, [\n",
    "#             n_valid_examples,\n",
    "#             inference.IMAGE_SIZE,\n",
    "#             inference.IMAGE_SIZE,\n",
    "#             inference.NUM_CHANNELS],\n",
    "#         name='x-input')\n",
    "#         y_ = tf.placeholder(tf.float32, [None, inference.OUTPUT_NODE], name='y-input')\n",
    "#         validate_feed = {x: valid_data[0], y_: valid_data[1]}\n",
    "\n",
    "#         y = inference.inference(x, False, None)\n",
    "#         #预测值y和真实值y_中相同的为1，不同的为0\n",
    "#         correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "#         #将数组求平均值，得到预测结果的准确率即为神经网络的准确率\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "#         variable_averages = tf.train.ExponentialMovingAverage(train.MOVING_AVERAGE_DECAY)\n",
    "#         variables_to_restore = variable_averages.variables_to_restore()\n",
    "#         saver = tf.train.Saver(variables_to_restore)\n",
    "        \n",
    "#         while True:\n",
    "#             with tf.Session() as sess:\n",
    "#                 ckpt = tf.train.get_checkpoint_state(train.MODEL_SAVE_PATH)\n",
    "#                 if ckpt and ckpt.model_checkpoint_path:\n",
    "#                     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "#                     global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "#                     accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n",
    "#                     print(\"After %s training step(s), validation accuracy = %g\" % (global_step, accuracy_score))\n",
    "#                 else:\n",
    "#                     print('No checkpoint file found')\n",
    "#                     return\n",
    "#             time.sleep(EVAL_INTERVAL_SECS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(photo_data):\n",
    "    n_valid_examples = len(photo_data[0])\n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, [\n",
    "            n_valid_examples,\n",
    "            inference.IMAGE_SIZE,\n",
    "            inference.IMAGE_SIZE,\n",
    "            inference.NUM_CHANNELS],\n",
    "        name='x-input')\n",
    "        y_ = tf.placeholder(tf.float32, [None, inference.OUTPUT_NODE], name='y-input')\n",
    "        validate_feed = {x: photo_data[0], y_: photo_data[1]}\n",
    "        #训练集\n",
    "        train_feed = {x: photo_data[2], y_: photo_data[3]}\n",
    "        y = inference.inference(x, False, None)\n",
    "        #预测值y和真实值y_中相同的为1，不同的为0\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        #将数组求平均值，得到预测结果的准确率即为神经网络的准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        variable_averages = tf.train.ExponentialMovingAverage(train.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "        \n",
    "        # while True:\n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state(train.MODEL_SAVE_PATH)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                accuracy_score_valid = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                accuracy_score_train = sess.run(accuracy, feed_dict=train_feed)\n",
    "                print(\"After %s training step(s), validation accuracy = %g\" % (global_step, accuracy_score_valid))\n",
    "                print(\"After %s training step(s), training accuracy = %g\" % (global_step, accuracy_score_train))\n",
    "            else:\n",
    "                print('No checkpoint file found')\n",
    "                return\n",
    "            # time.sleep(EVAL_INTERVAL_SECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     photo_data = np.load(train.INPUT_DATA)\n",
    "#     valid_images = np.asarray(photo_data[2])\n",
    "#     valid_labels = np.asarray(photo_data[3])\n",
    "#     test_images = np.asarray(photo_data[4])\n",
    "#     test_labels = np.asarray(photo_data[5])\n",
    "#     print(\"%d training examples, %d validation examples and %d testing examples.\" % (\n",
    "#         len(photo_data[0]), len(photo_data[2]), len(photo_data[4])))\n",
    "    \n",
    "#     valid_images = np.vstack((valid_images,test_images))\n",
    "#     valid_labels = np.vstack((valid_labels, test_labels))\n",
    "# #     valid_images = np.asarray(valid_images)\n",
    "# #     valid_labels = np.asarray(valid_labels)\n",
    "#     print(type(valid_labels),valid_labels.shape)\n",
    "    \n",
    "#     evaluate([valid_images,valid_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 training examples, 23 validation examples and 40 testing examples.\n",
      "<class 'numpy.ndarray'> (63, 40)\n",
      "(63, 40)\n",
      "INFO:tensorflow:Restoring parameters from ./model/face_model.ckpt-4000\n",
      "After 4000 training step(s), validation accuracy = 0.904762\n",
      "After 4000 training step(s), training accuracy = 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    photo_data = np.load(train.INPUT_DATA)\n",
    "    valid_images = np.asarray(photo_data[2])\n",
    "    valid_labels = np.asarray(photo_data[3])\n",
    "    test_images = np.asarray(photo_data[4])\n",
    "    test_labels = np.asarray(photo_data[5])\n",
    "    print(\"%d training examples, %d validation examples and %d testing examples.\" % (\n",
    "        len(photo_data[0]), len(photo_data[2]), len(photo_data[4])))\n",
    "    #合并valid与test\n",
    "    valid_images = np.vstack((valid_images,test_images))\n",
    "    valid_labels = np.vstack((valid_labels, test_labels))\n",
    "    n_valid_examples = len(valid_images)\n",
    "    print(type(valid_labels),valid_labels.shape)\n",
    "    \n",
    "    train_images = np.asarray(photo_data[0][:n_valid_examples])\n",
    "    train_labels = np.asarray(photo_data[1][:n_valid_examples])\n",
    "    print(train_labels.shape)\n",
    "    evaluate([valid_images,valid_labels,train_images,train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
